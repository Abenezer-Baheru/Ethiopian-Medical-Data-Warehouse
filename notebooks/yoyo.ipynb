{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Use the Pre-trained YOLOv8 Model to Detect Objects in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\10.jpg: 640x640 1 toilet, 508.6ms\n",
      "Speed: 13.0ms preprocess, 508.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\11.jpg: 640x640 (no detections), 432.8ms\n",
      "Speed: 13.0ms preprocess, 432.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13.jpg: 640x640 (no detections), 431.8ms\n",
      "Speed: 11.0ms preprocess, 431.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13010.jpg: 640x640 (no detections), 448.8ms\n",
      "Speed: 11.0ms preprocess, 448.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13011.jpg: 640x640 (no detections), 461.8ms\n",
      "Speed: 9.0ms preprocess, 461.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13012.jpg: 640x640 (no detections), 474.7ms\n",
      "Speed: 15.0ms preprocess, 474.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13013.jpg: 640x640 (no detections), 431.8ms\n",
      "Speed: 11.0ms preprocess, 431.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13014.jpg: 640x640 1 cell phone, 437.8ms\n",
      "Speed: 9.0ms preprocess, 437.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13015.jpg: 640x640 (no detections), 431.9ms\n",
      "Speed: 13.0ms preprocess, 431.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13016.jpg: 640x640 1 traffic light, 533.6ms\n",
      "Speed: 11.0ms preprocess, 533.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13017.jpg: 512x640 (no detections), 402.9ms\n",
      "Speed: 8.0ms preprocess, 402.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13018.jpg: 640x640 (no detections), 462.8ms\n",
      "Speed: 13.0ms preprocess, 462.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13019.jpg: 640x640 1 frisbee, 1 bottle, 1 clock, 430.9ms\n",
      "Speed: 11.0ms preprocess, 430.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13020.jpg: 640x544 1 bottle, 386.0ms\n",
      "Speed: 8.0ms preprocess, 386.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13021.jpg: 640x640 1 teddy bear, 449.8ms\n",
      "Speed: 9.0ms preprocess, 449.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13022.jpg: 640x640 1 bus, 428.9ms\n",
      "Speed: 10.0ms preprocess, 428.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13023.jpg: 640x640 (no detections), 420.9ms\n",
      "Speed: 11.0ms preprocess, 420.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13024.jpg: 640x640 1 book, 440.8ms\n",
      "Speed: 11.0ms preprocess, 440.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13025.jpg: 640x640 1 bottle, 417.9ms\n",
      "Speed: 11.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13026.jpg: 640x640 1 book, 420.9ms\n",
      "Speed: 8.0ms preprocess, 420.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13027.jpg: 640x448 (no detections), 338.1ms\n",
      "Speed: 6.0ms preprocess, 338.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13028.jpg: 640x640 1 remote, 429.9ms\n",
      "Speed: 11.0ms preprocess, 429.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13029.jpg: 640x640 1 remote, 420.9ms\n",
      "Speed: 8.0ms preprocess, 420.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13030.jpg: 640x640 1 refrigerator, 431.8ms\n",
      "Speed: 10.0ms preprocess, 431.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13031.jpg: 640x640 (no detections), 427.9ms\n",
      "Speed: 10.0ms preprocess, 427.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13032.jpg: 640x640 (no detections), 451.8ms\n",
      "Speed: 13.0ms preprocess, 451.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13033.jpg: 640x640 (no detections), 415.9ms\n",
      "Speed: 9.0ms preprocess, 415.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13034.jpg: 640x640 (no detections), 422.9ms\n",
      "Speed: 8.0ms preprocess, 422.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13035.jpg: 640x640 1 cup, 413.9ms\n",
      "Speed: 10.0ms preprocess, 413.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13036.jpg: 640x640 1 bus, 419.9ms\n",
      "Speed: 11.0ms preprocess, 419.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13037.jpg: 640x640 1 person, 420.9ms\n",
      "Speed: 10.0ms preprocess, 420.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13038.jpg: 640x640 1 person, 417.9ms\n",
      "Speed: 10.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13039.jpg: 640x640 (no detections), 422.9ms\n",
      "Speed: 9.0ms preprocess, 422.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13040.jpg: 640x640 (no detections), 422.9ms\n",
      "Speed: 9.0ms preprocess, 422.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13041.jpg: 640x640 (no detections), 445.8ms\n",
      "Speed: 32.9ms preprocess, 445.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13042.jpg: 640x480 1 bottle, 324.1ms\n",
      "Speed: 5.0ms preprocess, 324.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13043.jpg: 640x640 2 bottles, 414.9ms\n",
      "Speed: 8.0ms preprocess, 414.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13044.jpg: 640x640 1 bottle, 418.9ms\n",
      "Speed: 8.0ms preprocess, 418.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13045.jpg: 640x640 2 bottles, 495.7ms\n",
      "Speed: 9.0ms preprocess, 495.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13046.jpg: 640x640 1 bottle, 457.8ms\n",
      "Speed: 7.0ms preprocess, 457.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13047.jpg: 640x640 1 bottle, 447.8ms\n",
      "Speed: 11.0ms preprocess, 447.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13048.jpg: 640x640 1 bottle, 435.8ms\n",
      "Speed: 9.0ms preprocess, 435.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13049.jpg: 640x640 (no detections), 435.8ms\n",
      "Speed: 15.0ms preprocess, 435.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13050.jpg: 640x640 1 cup, 455.8ms\n",
      "Speed: 9.0ms preprocess, 455.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13051.jpg: 640x640 (no detections), 429.9ms\n",
      "Speed: 11.0ms preprocess, 429.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13052.jpg: 640x640 1 cell phone, 434.8ms\n",
      "Speed: 11.0ms preprocess, 434.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13053.jpg: 640x640 (no detections), 468.7ms\n",
      "Speed: 10.0ms preprocess, 468.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13054.jpg: 640x640 (no detections), 432.8ms\n",
      "Speed: 7.0ms preprocess, 432.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13055.jpg: 640x640 (no detections), 441.8ms\n",
      "Speed: 8.0ms preprocess, 441.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13056.jpg: 640x640 1 teddy bear, 431.9ms\n",
      "Speed: 10.0ms preprocess, 431.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13057.jpg: 640x640 1 stop sign, 428.9ms\n",
      "Speed: 11.0ms preprocess, 428.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13058.jpg: 640x448 (no detections), 322.1ms\n",
      "Speed: 4.0ms preprocess, 322.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13059.jpg: 640x640 6 suitcases, 7 bottles, 435.8ms\n",
      "Speed: 10.0ms preprocess, 435.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13060.jpg: 640x640 1 person, 437.8ms\n",
      "Speed: 10.0ms preprocess, 437.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13061.jpg: 640x640 (no detections), 450.8ms\n",
      "Speed: 9.0ms preprocess, 450.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13062.jpg: 640x640 (no detections), 429.9ms\n",
      "Speed: 11.0ms preprocess, 429.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13063.jpg: 640x640 (no detections), 436.8ms\n",
      "Speed: 9.0ms preprocess, 436.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13064.jpg: 640x640 (no detections), 438.8ms\n",
      "Speed: 10.0ms preprocess, 438.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13065.jpg: 640x640 1 cup, 433.8ms\n",
      "Speed: 10.0ms preprocess, 433.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13066.jpg: 640x640 1 bus, 452.8ms\n",
      "Speed: 10.0ms preprocess, 452.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13067.jpg: 640x640 1 person, 484.7ms\n",
      "Speed: 12.0ms preprocess, 484.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13068.jpg: 640x640 (no detections), 444.8ms\n",
      "Speed: 11.0ms preprocess, 444.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13069.jpg: 640x640 (no detections), 426.9ms\n",
      "Speed: 10.0ms preprocess, 426.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13070.jpg: 576x640 1 book, 430.9ms\n",
      "Speed: 11.0ms preprocess, 430.9ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13071.jpg: 576x640 1 book, 388.0ms\n",
      "Speed: 10.0ms preprocess, 388.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13072.jpg: 640x640 (no detections), 509.6ms\n",
      "Speed: 11.0ms preprocess, 509.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13073.jpg: 640x640 (no detections), 420.9ms\n",
      "Speed: 12.0ms preprocess, 420.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13074.jpg: 640x640 1 cup, 429.9ms\n",
      "Speed: 8.0ms preprocess, 429.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13075.jpg: 544x640 (no detections), 369.0ms\n",
      "Speed: 6.0ms preprocess, 369.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13076.jpg: 640x640 1 dining table, 421.9ms\n",
      "Speed: 11.0ms preprocess, 421.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13077.jpg: 640x640 (no detections), 435.8ms\n",
      "Speed: 11.0ms preprocess, 435.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13078.jpg: 640x640 1 person, 1 bowl, 425.9ms\n",
      "Speed: 10.0ms preprocess, 425.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13079.jpg: 640x640 2 cakes, 434.8ms\n",
      "Speed: 11.0ms preprocess, 434.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13080.jpg: 640x640 1 cup, 1 book, 431.8ms\n",
      "Speed: 12.0ms preprocess, 431.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13081.jpg: 640x640 1 knife, 1 toilet, 424.9ms\n",
      "Speed: 10.0ms preprocess, 424.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13082.jpg: 640x640 (no detections), 419.9ms\n",
      "Speed: 11.0ms preprocess, 419.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13083.jpg: 640x640 1 cup, 431.9ms\n",
      "Speed: 9.0ms preprocess, 431.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13084.jpg: 640x640 (no detections), 428.9ms\n",
      "Speed: 11.0ms preprocess, 428.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13085.jpg: 640x640 1 cup, 437.8ms\n",
      "Speed: 10.0ms preprocess, 437.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13086.jpg: 640x640 (no detections), 426.9ms\n",
      "Speed: 10.0ms preprocess, 426.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13087.jpg: 640x640 (no detections), 423.9ms\n",
      "Speed: 10.0ms preprocess, 423.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13088.jpg: 640x640 (no detections), 461.8ms\n",
      "Speed: 11.0ms preprocess, 461.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13089.jpg: 640x640 (no detections), 496.7ms\n",
      "Speed: 12.0ms preprocess, 496.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13090.jpg: 640x640 1 cup, 542.6ms\n",
      "Speed: 11.0ms preprocess, 542.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13091.jpg: 640x640 1 bus, 455.8ms\n",
      "Speed: 14.0ms preprocess, 455.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13092.jpg: 640x640 (no detections), 428.9ms\n",
      "Speed: 9.0ms preprocess, 428.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13093.jpg: 640x640 1 bottle, 446.8ms\n",
      "Speed: 10.0ms preprocess, 446.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13095.jpg: 640x640 (no detections), 441.8ms\n",
      "Speed: 10.0ms preprocess, 441.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13096.jpg: 640x480 1 bottle, 1 cake, 361.0ms\n",
      "Speed: 6.0ms preprocess, 361.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13097.jpg: 640x640 1 bottle, 487.7ms\n",
      "Speed: 12.0ms preprocess, 487.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13098.jpg: 640x640 1 bottle, 428.9ms\n",
      "Speed: 12.0ms preprocess, 428.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13099.jpg: 640x640 1 bottle, 1 apple, 427.9ms\n",
      "Speed: 10.0ms preprocess, 427.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13100.jpg: 640x640 (no detections), 423.9ms\n",
      "Speed: 7.0ms preprocess, 423.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13101.jpg: 640x640 1 bottle, 499.7ms\n",
      "Speed: 13.0ms preprocess, 499.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13102.jpg: 640x640 1 bottle, 426.9ms\n",
      "Speed: 12.0ms preprocess, 426.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13103.jpg: 640x608 1 apple, 1 donut, 435.8ms\n",
      "Speed: 10.0ms preprocess, 435.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13104.jpg: 640x544 (no detections), 371.0ms\n",
      "Speed: 10.0ms preprocess, 371.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\13105.jpg: 640x640 (no detections), 425.9ms\n",
      "Speed: 11.0ms preprocess, 425.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\14.jpg: 640x480 (no detections), 334.1ms\n",
      "Speed: 4.0ms preprocess, 334.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\15.jpg: 640x640 (no detections), 458.8ms\n",
      "Speed: 11.0ms preprocess, 458.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\17.jpg: 640x480 11 bottles, 339.1ms\n",
      "Speed: 6.0ms preprocess, 339.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\18.jpg: 544x640 (no detections), 396.9ms\n",
      "Speed: 8.0ms preprocess, 396.9ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\19.jpg: 480x640 3 persons, 1 chair, 1 dining table, 376.0ms\n",
      "Speed: 5.0ms preprocess, 376.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\2.jpg: 544x640 1 sports ball, 1 bottle, 372.0ms\n",
      "Speed: 8.0ms preprocess, 372.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\20.jpg: 480x640 3 persons, 1 chair, 1 dining table, 332.1ms\n",
      "Speed: 4.0ms preprocess, 332.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\21.jpg: 640x640 (no detections), 423.9ms\n",
      "Speed: 8.0ms preprocess, 423.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\22.jpg: 544x640 2 cell phones, 1 book, 404.9ms\n",
      "Speed: 9.0ms preprocess, 404.9ms inference, 3.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\23.jpg: 544x640 1 cell phone, 380.0ms\n",
      "Speed: 11.0ms preprocess, 380.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\25.jpg: 544x640 1 person, 1 cell phone, 369.0ms\n",
      "Speed: 10.0ms preprocess, 369.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\26.jpg: 544x640 1 person, 367.0ms\n",
      "Speed: 9.0ms preprocess, 367.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\27.jpg: 544x640 (no detections), 366.0ms\n",
      "Speed: 9.0ms preprocess, 366.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\29.jpg: 640x480 1 person, 332.1ms\n",
      "Speed: 6.0ms preprocess, 332.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\3.jpg: 640x640 (no detections), 413.9ms\n",
      "Speed: 12.0ms preprocess, 413.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\30.jpg: 544x640 1 person, 360.0ms\n",
      "Speed: 9.0ms preprocess, 360.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\31.jpg: 640x480 11 bottles, 1 cup, 330.1ms\n",
      "Speed: 5.0ms preprocess, 330.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\32.jpg: 544x640 1 person, 365.0ms\n",
      "Speed: 10.0ms preprocess, 365.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\33.jpg: 544x640 3 oranges, 363.0ms\n",
      "Speed: 9.0ms preprocess, 363.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\34.jpg: 544x640 (no detections), 360.0ms\n",
      "Speed: 10.0ms preprocess, 360.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\38.jpg: 544x640 2 toothbrushs, 359.1ms\n",
      "Speed: 9.0ms preprocess, 359.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\39.jpg: 320x640 5 mouses, 258.3ms\n",
      "Speed: 3.0ms preprocess, 258.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\40.jpg: 352x640 10 persons, 282.2ms\n",
      "Speed: 4.0ms preprocess, 282.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\41.jpg: 640x640 1 person, 1 remote, 429.9ms\n",
      "Speed: 12.0ms preprocess, 429.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\43.jpg: 640x640 1 person, 1 chair, 1 laptop, 1 keyboard, 415.9ms\n",
      "Speed: 12.0ms preprocess, 415.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\44.jpg: 384x640 1 person, 1 cell phone, 302.2ms\n",
      "Speed: 4.0ms preprocess, 302.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\45.jpg: 640x640 1 scissors, 451.8ms\n",
      "Speed: 11.0ms preprocess, 451.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\46.jpg: 640x640 2 persons, 1 toothbrush, 412.9ms\n",
      "Speed: 13.0ms preprocess, 412.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\48.jpg: 640x640 (no detections), 418.9ms\n",
      "Speed: 10.0ms preprocess, 418.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\49.jpg: 640x640 3 kites, 1 cake, 419.9ms\n",
      "Speed: 12.0ms preprocess, 419.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\50.jpg: 640x640 1 cake, 424.9ms\n",
      "Speed: 13.0ms preprocess, 424.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\52.jpg: 640x640 4 persons, 1 horse, 414.9ms\n",
      "Speed: 11.0ms preprocess, 414.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\53.jpg: 544x640 (no detections), 362.0ms\n",
      "Speed: 10.0ms preprocess, 362.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\55.jpg: 640x640 1 stop sign, 417.9ms\n",
      "Speed: 12.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\56.jpg: 640x640 1 person, 415.9ms\n",
      "Speed: 9.0ms preprocess, 415.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\58.jpg: 544x640 1 sports ball, 1 bottle, 367.0ms\n",
      "Speed: 9.0ms preprocess, 367.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\59.jpg: 640x640 1 bottle, 417.9ms\n",
      "Speed: 12.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\60.jpg: 640x640 (no detections), 414.9ms\n",
      "Speed: 12.0ms preprocess, 414.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\64.jpg: 640x640 1 person, 1 frisbee, 1 banana, 413.9ms\n",
      "Speed: 13.0ms preprocess, 413.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\67.jpg: 640x640 1 stop sign, 415.9ms\n",
      "Speed: 12.0ms preprocess, 415.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\70.jpg: 640x384 1 person, 2 potted plants, 308.2ms\n",
      "Speed: 3.0ms preprocess, 308.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\71.jpg: 640x288 2 persons, 1 sports ball, 244.3ms\n",
      "Speed: 8.0ms preprocess, 244.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\74.jpg: 640x640 1 toothbrush, 426.9ms\n",
      "Speed: 11.0ms preprocess, 426.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\75.jpg: 640x640 1 person, 417.9ms\n",
      "Speed: 13.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\76.jpg: 640x352 1 person, 1 bench, 3 chairs, 291.2ms\n",
      "Speed: 3.0ms preprocess, 291.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 352)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\77.jpg: 640x640 4 bottles, 507.6ms\n",
      "Speed: 12.0ms preprocess, 507.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\78.jpg: 640x480 1 person, 328.1ms\n",
      "Speed: 4.0ms preprocess, 328.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\79.jpg: 640x640 1 potted plant, 415.9ms\n",
      "Speed: 12.0ms preprocess, 415.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\80.jpg: 640x480 1 person, 1 bottle, 1 chair, 2 potted plants, 1 vase, 325.1ms\n",
      "Speed: 5.0ms preprocess, 325.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\81.jpg: 640x640 5 bottles, 443.8ms\n",
      "Speed: 12.0ms preprocess, 443.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\82.jpg: 640x640 4 bottles, 1 mouse, 416.9ms\n",
      "Speed: 13.0ms preprocess, 416.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\85.jpg: 640x640 (no detections), 427.9ms\n",
      "Speed: 9.0ms preprocess, 427.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\86.jpg: 640x640 1 person, 417.9ms\n",
      "Speed: 10.0ms preprocess, 417.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\87.jpg: 640x640 (no detections), 417.9ms\n",
      "Speed: 12.0ms preprocess, 417.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\88.jpg: 640x640 (no detections), 416.9ms\n",
      "Speed: 10.0ms preprocess, 416.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\9.jpg: 544x640 1 sports ball, 1 bottle, 364.0ms\n",
      "Speed: 9.0ms preprocess, 364.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\90.jpg: 640x640 1 bottle, 1 book, 414.9ms\n",
      "Speed: 12.0ms preprocess, 414.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\91.jpg: 640x640 (no detections), 418.9ms\n",
      "Speed: 12.0ms preprocess, 418.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\92.jpg: 640x640 1 person, 418.9ms\n",
      "Speed: 11.0ms preprocess, 418.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\93.jpg: 640x640 1 person, 1 cell phone, 418.9ms\n",
      "Speed: 12.0ms preprocess, 418.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\94.jpg: 640x640 1 person, 2 cups, 1 sandwich, 434.8ms\n",
      "Speed: 12.0ms preprocess, 434.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\95.jpg: 640x640 1 person, 415.9ms\n",
      "Speed: 10.0ms preprocess, 415.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\96.jpg: 640x640 (no detections), 416.9ms\n",
      "Speed: 11.0ms preprocess, 416.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\OnlineClass\\AIM\\Ethiopian-Medical-Data-Warehouse\\notebooks\\..\\src\\data\\images\\97.jpg: 640x640 (no detections), 457.8ms\n",
      "Speed: 10.0ms preprocess, 457.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed all images (162 images) in the directory.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load the pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = '../src/data/images'\n",
    "\n",
    "# Variable to store detection results\n",
    "results = []\n",
    "\n",
    "# Function to perform object detection on an image\n",
    "def detect_objects(image_path):\n",
    "    # Perform object detection\n",
    "    result = model(image_path)\n",
    "    return result\n",
    "\n",
    "# Process all images in the directory\n",
    "image_count = 0\n",
    "for image_file in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    result = detect_objects(image_path)\n",
    "    results.append(result)\n",
    "    image_count += 1\n",
    "\n",
    "print(f\"Processed all images ({image_count} images) in the directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Process the Detection Results\n",
    "\n",
    "Extract Relevant Data: Extract relevant data from the detection results, such as bounding box coordinates, confidence scores, and class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[893, 198, 1079, 412]</td>\n",
       "      <td>0.291480</td>\n",
       "      <td>61</td>\n",
       "      <td>toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[117, 70, 266, 363]</td>\n",
       "      <td>0.586576</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[263, 181, 296, 265]</td>\n",
       "      <td>0.574736</td>\n",
       "      <td>9</td>\n",
       "      <td>traffic light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[37, 808, 293, 1436]</td>\n",
       "      <td>0.610532</td>\n",
       "      <td>39</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1037, 355, 1308, 623]</td>\n",
       "      <td>0.558808</td>\n",
       "      <td>74</td>\n",
       "      <td>clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>[706, 547, 856, 826]</td>\n",
       "      <td>0.848834</td>\n",
       "      <td>41</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>[0, 626, 397, 864]</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>[861, 554, 1011, 838]</td>\n",
       "      <td>0.587011</td>\n",
       "      <td>41</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>[531, 593, 723, 766]</td>\n",
       "      <td>0.421497</td>\n",
       "      <td>48</td>\n",
       "      <td>sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>[16, 242, 708, 1076]</td>\n",
       "      <td>0.939469</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               bounding_box  confidence  class_id     class_name\n",
       "0     [893, 198, 1079, 412]    0.291480        61         toilet\n",
       "1       [117, 70, 266, 363]    0.586576        67     cell phone\n",
       "2      [263, 181, 296, 265]    0.574736         9  traffic light\n",
       "3      [37, 808, 293, 1436]    0.610532        39         bottle\n",
       "4    [1037, 355, 1308, 623]    0.558808        74          clock\n",
       "..                      ...         ...       ...            ...\n",
       "215    [706, 547, 856, 826]    0.848834        41            cup\n",
       "216      [0, 626, 397, 864]    0.754615         0         person\n",
       "217   [861, 554, 1011, 838]    0.587011        41            cup\n",
       "218    [531, 593, 723, 766]    0.421497        48       sandwich\n",
       "219    [16, 242, 708, 1076]    0.939469         0         person\n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Class names for YOLOv8 (COCO dataset)\n",
    "class_names = model.names\n",
    "\n",
    "def extract_detection_data(results):\n",
    "    detection_data = []\n",
    "    for result in results:\n",
    "        for box in result[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            confidence = box.conf[0].item()\n",
    "            class_id = int(box.cls[0].item())\n",
    "            class_name = class_names[class_id]\n",
    "            detection_data.append({\n",
    "                'bounding_box': [x1, y1, x2, y2],\n",
    "                'confidence': confidence,\n",
    "                'class_id': class_id,\n",
    "                'class_name': class_name\n",
    "            })\n",
    "    return detection_data\n",
    "\n",
    "# Example usage\n",
    "detection_data = extract_detection_data(results)\n",
    "\n",
    "# Convert to DataFrame and display the head\n",
    "df = pd.DataFrame(detection_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: Store Detection Data in a Database Table\n",
    "\n",
    "Set Up the Database: Configure the database connection using SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abeni\\AppData\\Local\\Temp\\ipykernel_15824\\3446258634.py:8: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, Float, String, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Database configuration\n",
    "DATABASE_URL = 'postgresql://postgres:abeni@localhost:5432/telegram_data'\n",
    "engine = create_engine(DATABASE_URL)\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the DetectionData model\n",
    "class DetectionData(Base):\n",
    "    __tablename__ = 'detection_data'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    bounding_box = Column(JSON)\n",
    "    confidence = Column(Float)\n",
    "    class_id = Column(Integer)\n",
    "    class_name = Column(String)\n",
    "    image_path = Column(String)\n",
    "\n",
    "# Create the table\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Detection Data: Insert the extracted detection data into the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_detection_data(session, detection_data, image_path):\n",
    "    for data in detection_data:\n",
    "        detection_record = DetectionData(\n",
    "            bounding_box=data['bounding_box'],\n",
    "            confidence=data['confidence'],\n",
    "            class_id=data['class_id'],\n",
    "            class_name=data['class_name'],\n",
    "            image_path=image_path\n",
    "        )\n",
    "        session.add(detection_record)\n",
    "    session.commit()\n",
    "\n",
    "# Example usage\n",
    "insert_detection_data(session, detection_data, image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
